"""
APIæ•°æ®ç”Ÿæˆå™¨ - ä¸ºæŠ€æœ¯è§†é‡åŠ©æ‰‹ç”ŸæˆJSON APIæ•°æ®
"""

import json
import os
from datetime import datetime

class APIGenerator:
    def __init__(self):
        self.api_version = "1.0"
        self.base_structure = {
            "meta": {
                "version": self.api_version,
                "generated_at": "",
                "update_frequency": "daily",
                "next_update": "",
                "total_sources": 0,
                "status": "active"
            },
            "data": {},
            "statistics": {},
            "endpoints": {
                "all": "/api/all.json",
                "ai_news": "/api/ai_news.json",
                "tech_news": "/api/tech_news.json",
                "security_news": "/api/security_news.json",
                "github_trending": "/api/github_trending.json",
                "tech_trends": "/api/tech_trends.json",
                "dev_tools": "/api/dev_tools.json"
            }
        }
    
    def generate_api_data(self, data_dict):
        """ç”Ÿæˆå®Œæ•´çš„APIæ•°æ®ç»“æ„"""
        current_time = datetime.now()
        
        api_data = self.base_structure.copy()
        api_data["meta"]["generated_at"] = current_time.isoformat()
        api_data["meta"]["next_update"] = current_time.replace(
            hour=8, minute=0, second=0, microsecond=0
        ).isoformat()
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total_news": 0,
            "ai_news_count": len(data_dict.get('ai_news', [])),
            "tech_news_count": len(data_dict.get('tech_news', [])),
            "security_news_count": len(data_dict.get('security_news', [])),
            "github_repos_count": len(data_dict.get('github_repos', [])),
            "tech_trends_count": len(data_dict.get('tech_trends', [])),
            "dev_tools_count": len(data_dict.get('dev_tools', [])),
            "sentiment_analysis": {
                "positive": 0,
                "negative": 0,
                "neutral": 0
            }
        }
        
        stats["total_news"] = (stats["ai_news_count"] + 
                              stats["tech_news_count"] + 
                              stats["security_news_count"])
        
        api_data["statistics"] = stats
        api_data["data"] = data_dict
        api_data["meta"]["total_sources"] = len([k for k in data_dict.keys() if data_dict[k]])
        
        return api_data
    
    def save_api_files(self, data_dict):
        """ä¿å­˜å„ç§APIæ–‡ä»¶"""
        # ç¡®ä¿APIç›®å½•å­˜åœ¨
        api_dir = "docs/api"
        os.makedirs(api_dir, exist_ok=True)
        
        # ç”Ÿæˆä¸»APIæ–‡ä»¶
        main_api_data = self.generate_api_data(data_dict)
        self.save_json_file(main_api_data, f"{api_dir}/all.json")
        
        # ç”Ÿæˆåˆ†ç±»APIæ–‡ä»¶
        categories = {
            "ai_news": "AIæŠ€æœ¯åŠ¨æ€",
            "tech_news": "ç§‘æŠ€çƒ­ç‚¹",
            "security_news": "ç½‘ç»œå®‰å…¨èµ„è®¯",
            "github_repos": "GitHubè¶‹åŠ¿é¡¹ç›®",
            "tech_trends": "æŠ€æœ¯çƒ­è¯è¶‹åŠ¿",
            "dev_tools": "å¼€å‘è€…å·¥å…·æ¨è"
        }
        
        for category, title in categories.items():
            if category in data_dict and data_dict[category]:
                category_data = {
                    "meta": {
                        "category": category,
                        "title": title,
                        "generated_at": datetime.now().isoformat(),
                        "count": len(data_dict[category])
                    },
                    "data": data_dict[category]
                }
                self.save_json_file(category_data, f"{api_dir}/{category}.json")
        
        # ç”ŸæˆAPIæ–‡æ¡£
        self.generate_api_docs(api_dir)
        
        print(f"APIæ–‡ä»¶å·²ç”Ÿæˆåˆ° {api_dir} ç›®å½•")
    
    def save_json_file(self, data, filepath):
        """ä¿å­˜JSONæ–‡ä»¶"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            return False
    
    def generate_api_docs(self, api_dir):
        """ç”ŸæˆAPIæ–‡æ¡£"""
        docs_content = """# æŠ€æœ¯è§†é‡åŠ©æ‰‹ API æ–‡æ¡£

## æ¦‚è¿°

æŠ€æœ¯è§†é‡åŠ©æ‰‹æä¾›RESTful APIæ¥å£ï¼Œæ–¹ä¾¿å¼€å‘è€…è·å–æœ€æ–°çš„æŠ€æœ¯èµ„è®¯æ•°æ®ã€‚

## åŸºç¡€ä¿¡æ¯

- **APIç‰ˆæœ¬**: v1.0
- **æ›´æ–°é¢‘ç‡**: æ¯æ—¥ 08:00 (UTC+8)
- **æ•°æ®æ ¼å¼**: JSON
- **å­—ç¬¦ç¼–ç **: UTF-8

## ç«¯ç‚¹åˆ—è¡¨

### 1. è·å–æ‰€æœ‰æ•°æ®
```
GET /api/all.json
```
è¿”å›æ‰€æœ‰ç±»åˆ«çš„å®Œæ•´æ•°æ®ï¼ŒåŒ…æ‹¬å…ƒæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯ã€‚

### 2. AIæŠ€æœ¯åŠ¨æ€
```
GET /api/ai_news.json
```
è¿”å›æœ€æ–°çš„AIæŠ€æœ¯ç›¸å…³æ–°é—»å’ŒåŠ¨æ€ã€‚

### 3. ç§‘æŠ€çƒ­ç‚¹
```
GET /api/tech_news.json
```
è¿”å›ç§‘æŠ€è¡Œä¸šçš„çƒ­ç‚¹æ–°é—»ã€‚

### 4. ç½‘ç»œå®‰å…¨èµ„è®¯
```
GET /api/security_news.json
```
è¿”å›ç½‘ç»œå®‰å…¨ç›¸å…³çš„èµ„è®¯å’Œè­¦æŠ¥ã€‚

### 5. GitHubè¶‹åŠ¿é¡¹ç›®
```
GET /api/github_repos.json
```
è¿”å›GitHubä¸Šçš„è¶‹åŠ¿å¼€æºé¡¹ç›®ã€‚

### 6. æŠ€æœ¯çƒ­è¯è¶‹åŠ¿
```
GET /api/tech_trends.json
```
è¿”å›æŠ€æœ¯å…³é”®è¯çš„çƒ­åº¦è¶‹åŠ¿åˆ†æã€‚

### 7. å¼€å‘è€…å·¥å…·æ¨è
```
GET /api/dev_tools.json
```
è¿”å›æ¨èçš„å¼€å‘è€…å·¥å…·å’Œèµ„æºã€‚

## æ•°æ®ç»“æ„

### ä¸»APIå“åº”ç»“æ„
```json
{
  "meta": {
    "version": "1.0",
    "generated_at": "2025-06-16T08:00:00",
    "update_frequency": "daily",
    "next_update": "2025-06-17T08:00:00",
    "total_sources": 6,
    "status": "active"
  },
  "data": {
    "ai_news": [...],
    "tech_news": [...],
    "security_news": [...],
    "github_repos": [...],
    "tech_trends": [...],
    "dev_tools": [...]
  },
  "statistics": {
    "total_news": 15,
    "ai_news_count": 5,
    "tech_news_count": 5,
    "security_news_count": 5,
    "github_repos_count": 5,
    "tech_trends_count": 5,
    "dev_tools_count": 3
  },
  "endpoints": {
    "all": "/api/all.json",
    "ai_news": "/api/ai_news.json",
    ...
  }
}
```

### æ–°é—»é¡¹ç›®ç»“æ„
```json
{
  "title": "æ–°é—»æ ‡é¢˜",
  "url": "https://example.com/news",
  "description": "æ–°é—»æè¿°",
  "sentiment": {
    "score": 0.5,
    "sentiment": "positive"
  },
  "hotness": {
    "score": 75,
    "level": "ğŸ”¥ğŸ”¥ å¾ˆçƒ­"
  }
}
```

## ä½¿ç”¨ç¤ºä¾‹

### JavaScript
```javascript
// è·å–æ‰€æœ‰æ•°æ®
fetch('/api/all.json')
  .then(response => response.json())
  .then(data => {
    console.log('æ€»æ–°é—»æ•°:', data.statistics.total_news);
    console.log('AIæ–°é—»:', data.data.ai_news);
  });

// è·å–ç‰¹å®šç±»åˆ«
fetch('/api/ai_news.json')
  .then(response => response.json())
  .then(data => {
    console.log('AIæ–°é—»æ•°é‡:', data.meta.count);
    data.data.forEach(news => {
      console.log(news.title);
    });
  });
```

### Python
```python
import requests

# è·å–æ‰€æœ‰æ•°æ®
response = requests.get('https://your-domain.com/api/all.json')
data = response.json()

print(f"æ€»æ–°é—»æ•°: {data['statistics']['total_news']}")
for news in data['data']['ai_news']:
    print(f"- {news['title']}")
```

### cURL
```bash
# è·å–æ‰€æœ‰æ•°æ®
curl -X GET "https://your-domain.com/api/all.json"

# è·å–AIæ–°é—»
curl -X GET "https://your-domain.com/api/ai_news.json"
```

## é”™è¯¯å¤„ç†

APIä½¿ç”¨æ ‡å‡†HTTPçŠ¶æ€ç ï¼š

- `200 OK`: è¯·æ±‚æˆåŠŸ
- `404 Not Found`: ç«¯ç‚¹ä¸å­˜åœ¨
- `500 Internal Server Error`: æœåŠ¡å™¨é”™è¯¯

## é™åˆ¶å’Œæ³¨æ„äº‹é¡¹

1. **æ›´æ–°é¢‘ç‡**: æ•°æ®æ¯æ—¥æ›´æ–°ä¸€æ¬¡
2. **ç¼“å­˜**: å»ºè®®å®¢æˆ·ç«¯ç¼“å­˜æ•°æ®ï¼Œé¿å…é¢‘ç¹è¯·æ±‚
3. **CORS**: APIæ”¯æŒè·¨åŸŸè¯·æ±‚
4. **å…è´¹ä½¿ç”¨**: å½“å‰APIå®Œå…¨å…è´¹ï¼Œæ— éœ€è®¤è¯

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡GitHub Issuesè”ç³»æˆ‘ä»¬ã€‚

---

*æœ€åæ›´æ–°: {update_time}*
""".format(update_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        
        try:
            with open(f"{api_dir}/README.md", 'w', encoding='utf-8') as f:
                f.write(docs_content)
            print("APIæ–‡æ¡£å·²ç”Ÿæˆ")
        except Exception as e:
            print(f"ç”ŸæˆAPIæ–‡æ¡£å¤±è´¥: {e}")

# åˆ›å»ºå…¨å±€å®ä¾‹
api_generator = APIGenerator()
